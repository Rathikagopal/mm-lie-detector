{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst import dl\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from mmcv.utils import Config\n",
    "\n",
    "from liedet.data import VideoReader\n",
    "from liedet.datasets import build_dataset\n",
    "from liedet.models.e2e import LieDetectorRunner\n",
    "from liedet.models.registry import build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video --> landmarks + angles --> transformer --> linear --> probs\n",
    "# cfg = \"configs/landmarks_transformer.py\"\n",
    "\n",
    "# video --> landmarks+angles -- \n",
    "#                              --> concat --> transformer --> linear --> probs\n",
    "# audio --> features ----------\n",
    "cfg = \"configs/landmarks_audio_transformer.py\"\n",
    "\n",
    "# video --> TinaFace --(faces) --> ResNet3D --> linear --> probs\n",
    "# cfg = \"confgis/tinaface_r3d.py\"\n",
    "\n",
    "# video --> TinaFace --(faces)--> TimeSformer --> linear --> probs\n",
    "# cfg = \"confgis/tinaface_timesformer.py\"\n",
    "\n",
    "# video --> TinaFace --(faces)--> ResNet50 --(face features)--> Transformer --> linear --> probs\n",
    "# cfg = \"confgis/tinaface_r50_transformer.py\"\n",
    "\n",
    "\n",
    "cfg = Config.fromfile(cfg)\n",
    "cfg[\"model\"].pop(\"init_cfg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(cfg.dataset)\n",
    "train_set, valid_set = dataset.split(**cfg.dataset.split)\n",
    "loaders = dict(\n",
    "    train_loader=DataLoader(train_set, batch_size=cfg.batch_size, num_workers=0, drop_last=True),\n",
    "    valid_loader=DataLoader(valid_set, batch_size=cfg.batch_size, num_workers=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build(cfg.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build optimizer and critetion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = LieDetectorRunner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    loaders=loaders,\n",
    "    logdir=\"./logs\",\n",
    "    num_epochs=200,\n",
    "    valid_loader=\"valid_loader\",\n",
    "    valid_metric=\"accuracy01\",\n",
    "    minimize_valid_metric=False,\n",
    "    callbacks=[\n",
    "        dl.CriterionCallback(input_key=\"logits\", target_key=\"labels\", metric_key=\"loss\"),\n",
    "        dl.BackwardCallback(metric_key=\"loss\"),\n",
    "        dl.OptimizerCallback(metric_key=\"loss\"),\n",
    "        dl.AccuracyCallback(input_key=\"logits\", target_key=\"labels\", num_classes=2),\n",
    "        dl.EarlyStoppingCallback(patience=15, loader_key=\"valid_loader\", metric_key=\"loss\", minimize=True),\n",
    "        dl.CheckpointCallback(\n",
    "            logdir=\"./logs\",\n",
    "            loader_key=\"valid_loader\",\n",
    "            metric_key=\"loss\",\n",
    "            minimize=True,\n",
    "            topk=1,\n",
    "        ),\n",
    "    ],\n",
    "    load_best_on_end=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model on valid loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.evaluate_loader(\n",
    "    loader=loaders[\"valid_loader\"],\n",
    "    callbacks=[\n",
    "        dl.BatchTransformCallback(\n",
    "            input_key=\"logits\", output_key=\"scores\", scope=\"on_batch_end\", transform=torch.sigmoid\n",
    "        ),\n",
    "        dl.AccuracyCallback(input_key=\"scores\", target_key=\"labels\", num_classes=2),\n",
    "    ],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer model on custom video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load video from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"assets/example.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr = VideoReader(uri=video_path, **cfg.dataset)\n",
    "length = len(vr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start in range(0, length, cfg.window):\n",
    "    sample = vr[start : start + cfg.window]\n",
    "\n",
    "    print(runner.predict_sample(sample))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
